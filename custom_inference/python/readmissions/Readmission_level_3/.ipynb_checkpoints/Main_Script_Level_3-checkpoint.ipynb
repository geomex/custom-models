{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler,OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: datarobot-drum in /Users/joel.gongora/opt/anaconda3/envs/drum_corrected/lib/python3.7/site-packages (1.5.11)\n",
      "Requirement already satisfied, skipping upgrade: scipy<2,>=1.1 in /Users/joel.gongora/opt/anaconda3/envs/drum_corrected/lib/python3.7/site-packages (from datarobot-drum) (1.7.1)\n",
      "Processing /Users/joel.gongora/Library/Caches/pip/wheels/4b/ec/62/dc7dab8452e83d6487282f0eed4fc0a01b94fefe50ceede3aa/strictyaml-1.4.2-cp37-none-any.whl\n",
      "Collecting argcomplete==1.11.1\n",
      "  Using cached argcomplete-1.11.1-py2.py3-none-any.whl (36 kB)\n",
      "Requirement already satisfied, skipping upgrade: memory-profiler<1.0.0 in /Users/joel.gongora/opt/anaconda3/envs/drum_corrected/lib/python3.7/site-packages (from datarobot-drum) (0.58.0)\n",
      "Collecting datarobot==2.24.0\n",
      "  Using cached datarobot-2.24.0-py3-none-any.whl (418 kB)\n",
      "Collecting julia==0.5.6\n",
      "  Using cached julia-0.5.6-py2.py3-none-any.whl (67 kB)\n",
      "Requirement already satisfied, skipping upgrade: flask in /Users/joel.gongora/opt/anaconda3/envs/drum_corrected/lib/python3.7/site-packages (from datarobot-drum) (2.0.1)\n",
      "Requirement already satisfied, skipping upgrade: jinja2 in /Users/joel.gongora/opt/anaconda3/envs/drum_corrected/lib/python3.7/site-packages (from datarobot-drum) (3.0.1)\n",
      "Requirement already satisfied, skipping upgrade: progress in /Users/joel.gongora/opt/anaconda3/envs/drum_corrected/lib/python3.7/site-packages (from datarobot-drum) (1.6)\n",
      "Requirement already satisfied, skipping upgrade: requests in /Users/joel.gongora/opt/anaconda3/envs/drum_corrected/lib/python3.7/site-packages (from datarobot-drum) (2.26.0)\n",
      "Requirement already satisfied, skipping upgrade: numpy in /Users/joel.gongora/opt/anaconda3/envs/drum_corrected/lib/python3.7/site-packages (from datarobot-drum) (1.19.5)\n",
      "Requirement already satisfied, skipping upgrade: py4j~=0.10.9.0 in /Users/joel.gongora/opt/anaconda3/envs/drum_corrected/lib/python3.7/site-packages (from datarobot-drum) (0.10.9.2)\n",
      "Collecting pyarrow==2.0.0\n",
      "  Using cached pyarrow-2.0.0-cp37-cp37m-macosx_10_13_x86_64.whl (13.4 MB)\n",
      "Requirement already satisfied, skipping upgrade: docker>=4.2.2<5.0.0 in /Users/joel.gongora/opt/anaconda3/envs/drum_corrected/lib/python3.7/site-packages (from datarobot-drum) (5.0.2)\n",
      "Collecting Pillow==8.2.0\n",
      "  Using cached Pillow-8.2.0-cp37-cp37m-macosx_10_10_x86_64.whl (2.8 MB)\n",
      "Requirement already satisfied, skipping upgrade: texttable in /Users/joel.gongora/opt/anaconda3/envs/drum_corrected/lib/python3.7/site-packages (from datarobot-drum) (1.6.4)\n",
      "Requirement already satisfied, skipping upgrade: mlpiper~=2.4.0 in /Users/joel.gongora/opt/anaconda3/envs/drum_corrected/lib/python3.7/site-packages (from datarobot-drum) (2.4.2)\n",
      "Requirement already satisfied, skipping upgrade: pandas<1.3.1,>=1.0.5 in /Users/joel.gongora/opt/anaconda3/envs/drum_corrected/lib/python3.7/site-packages (from datarobot-drum) (1.1.5)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil>=2.6.0 in /Users/joel.gongora/opt/anaconda3/envs/drum_corrected/lib/python3.7/site-packages (from strictyaml==1.4.2->datarobot-drum) (2.8.2)\n",
      "Collecting ruamel.yaml==0.17.4\n",
      "  Using cached ruamel.yaml-0.17.4-py3-none-any.whl (101 kB)\n",
      "Collecting importlib-metadata<2,>=0.23; python_version == \"3.7\"\n",
      "  Using cached importlib_metadata-1.7.0-py2.py3-none-any.whl (31 kB)\n",
      "Requirement already satisfied, skipping upgrade: psutil in /Users/joel.gongora/opt/anaconda3/envs/drum_corrected/lib/python3.7/site-packages (from memory-profiler<1.0.0->datarobot-drum) (5.8.0)\n",
      "Requirement already satisfied, skipping upgrade: requests-toolbelt>=0.6 in /Users/joel.gongora/opt/anaconda3/envs/drum_corrected/lib/python3.7/site-packages (from datarobot==2.24.0->datarobot-drum) (0.9.1)\n",
      "Requirement already satisfied, skipping upgrade: urllib3>=1.23 in /Users/joel.gongora/opt/anaconda3/envs/drum_corrected/lib/python3.7/site-packages (from datarobot==2.24.0->datarobot-drum) (1.26.6)\n",
      "Requirement already satisfied, skipping upgrade: attrs<20.0,>=19.1.0 in /Users/joel.gongora/opt/anaconda3/envs/drum_corrected/lib/python3.7/site-packages (from datarobot==2.24.0->datarobot-drum) (19.3.0)\n",
      "Requirement already satisfied, skipping upgrade: trafaret!=1.1.0,<2.0,>=0.7 in /Users/joel.gongora/opt/anaconda3/envs/drum_corrected/lib/python3.7/site-packages (from datarobot==2.24.0->datarobot-drum) (1.2.0)\n",
      "Requirement already satisfied, skipping upgrade: pyyaml>=3.11 in /Users/joel.gongora/opt/anaconda3/envs/drum_corrected/lib/python3.7/site-packages (from datarobot==2.24.0->datarobot-drum) (5.4.1)\n",
      "Requirement already satisfied, skipping upgrade: contextlib2>=0.5.5 in /Users/joel.gongora/opt/anaconda3/envs/drum_corrected/lib/python3.7/site-packages (from datarobot==2.24.0->datarobot-drum) (21.6.0)\n",
      "Requirement already satisfied, skipping upgrade: itsdangerous>=2.0 in /Users/joel.gongora/opt/anaconda3/envs/drum_corrected/lib/python3.7/site-packages (from flask->datarobot-drum) (2.0.1)\n",
      "Requirement already satisfied, skipping upgrade: Werkzeug>=2.0 in /Users/joel.gongora/opt/anaconda3/envs/drum_corrected/lib/python3.7/site-packages (from flask->datarobot-drum) (2.0.1)\n",
      "Requirement already satisfied, skipping upgrade: click>=7.1.2 in /Users/joel.gongora/opt/anaconda3/envs/drum_corrected/lib/python3.7/site-packages (from flask->datarobot-drum) (8.0.1)\n",
      "Requirement already satisfied, skipping upgrade: MarkupSafe>=2.0 in /Users/joel.gongora/opt/anaconda3/envs/drum_corrected/lib/python3.7/site-packages (from jinja2->datarobot-drum) (2.0.1)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /Users/joel.gongora/opt/anaconda3/envs/drum_corrected/lib/python3.7/site-packages (from requests->datarobot-drum) (2020.6.20)\n",
      "Requirement already satisfied, skipping upgrade: idna<4,>=2.5; python_version >= \"3\" in /Users/joel.gongora/opt/anaconda3/envs/drum_corrected/lib/python3.7/site-packages (from requests->datarobot-drum) (3.2)\n",
      "Requirement already satisfied, skipping upgrade: charset-normalizer~=2.0.0; python_version >= \"3\" in /Users/joel.gongora/opt/anaconda3/envs/drum_corrected/lib/python3.7/site-packages (from requests->datarobot-drum) (2.0.4)\n",
      "Requirement already satisfied, skipping upgrade: websocket-client>=0.32.0 in /Users/joel.gongora/opt/anaconda3/envs/drum_corrected/lib/python3.7/site-packages (from docker>=4.2.2<5.0.0->datarobot-drum) (1.2.1)\n",
      "Requirement already satisfied, skipping upgrade: future in /Users/joel.gongora/opt/anaconda3/envs/drum_corrected/lib/python3.7/site-packages (from mlpiper~=2.4.0->datarobot-drum) (0.18.2)\n",
      "Collecting flask-cors\n",
      "  Using cached Flask_Cors-3.0.10-py2.py3-none-any.whl (14 kB)\n",
      "Collecting uwsgi; sys_platform != \"win32\"\n",
      "  Using cached uWSGI-2.0.19.1.tar.gz (803 kB)\n",
      "Requirement already satisfied, skipping upgrade: termcolor in /Users/joel.gongora/opt/anaconda3/envs/drum_corrected/lib/python3.7/site-packages (from mlpiper~=2.4.0->datarobot-drum) (1.1.0)\n",
      "Requirement already satisfied, skipping upgrade: pytz>=2017.2 in /Users/joel.gongora/opt/anaconda3/envs/drum_corrected/lib/python3.7/site-packages (from pandas<1.3.1,>=1.0.5->datarobot-drum) (2021.1)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.5 in /Users/joel.gongora/opt/anaconda3/envs/drum_corrected/lib/python3.7/site-packages (from python-dateutil>=2.6.0->strictyaml==1.4.2->datarobot-drum) (1.15.0)\n",
      "Collecting ruamel.yaml.clib>=0.1.2; platform_python_implementation == \"CPython\" and python_version < \"3.10\"\n",
      "  Using cached ruamel.yaml.clib-0.2.6-cp37-cp37m-macosx_10_9_x86_64.whl (140 kB)\n",
      "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /Users/joel.gongora/opt/anaconda3/envs/drum_corrected/lib/python3.7/site-packages (from importlib-metadata<2,>=0.23; python_version == \"3.7\"->argcomplete==1.11.1->datarobot-drum) (3.3.1)\n",
      "Building wheels for collected packages: uwsgi\n",
      "  Building wheel for uwsgi (setup.py) ... \u001b[?25lerror\n",
      "\u001b[31m  ERROR: Command errored out with exit status 1:\n",
      "   command: /Users/joel.gongora/opt/anaconda3/envs/drum_corrected/bin/python -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/private/var/folders/nz/89yd1h313yn8t9lr6lw41zf80000gq/T/pip-install-5i6j2l6o/uwsgi/setup.py'\"'\"'; __file__='\"'\"'/private/var/folders/nz/89yd1h313yn8t9lr6lw41zf80000gq/T/pip-install-5i6j2l6o/uwsgi/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' bdist_wheel -d /private/var/folders/nz/89yd1h313yn8t9lr6lw41zf80000gq/T/pip-wheel-_o9j9e2k\n",
      "       cwd: /private/var/folders/nz/89yd1h313yn8t9lr6lw41zf80000gq/T/pip-install-5i6j2l6o/uwsgi/\n",
      "  Complete output (42 lines):\n",
      "  /Users/joel.gongora/opt/anaconda3/envs/drum_corrected/lib/python3.7/distutils/dist.py:274: UserWarning: Unknown distribution option: 'descriptions'\n",
      "    warnings.warn(msg)\n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running build_py\n",
      "  creating build\n",
      "  creating build/lib\n",
      "  copying uwsgidecorators.py -> build/lib\n",
      "  installing to build/bdist.macosx-10.7-x86_64/wheel\n",
      "  running install\n",
      "  using profile: buildconf/default.ini\n",
      "  detected include path: ['/usr/local/include', '/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/lib/clang/12.0.5/include', '/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX.sdk/usr/include', '/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include', '/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX.sdk/System/Library/Frameworks']\n",
      "  Traceback (most recent call last):\n",
      "    File \"/private/var/folders/nz/89yd1h313yn8t9lr6lw41zf80000gq/T/pip-install-5i6j2l6o/uwsgi/uwsgiconfig.py\", line 747, in __init__\n",
      "      gcc_version_components = gcc_version.split('.')\n",
      "  AttributeError: 'NoneType' object has no attribute 'split'\n",
      "  \n",
      "  During handling of the above exception, another exception occurred:\n",
      "  \n",
      "  Traceback (most recent call last):\n",
      "    File \"<string>\", line 1, in <module>\n",
      "    File \"/private/var/folders/nz/89yd1h313yn8t9lr6lw41zf80000gq/T/pip-install-5i6j2l6o/uwsgi/setup.py\", line 140, in <module>\n",
      "      'Programming Language :: Python :: 3.8',\n",
      "    File \"/Users/joel.gongora/opt/anaconda3/envs/drum_corrected/lib/python3.7/site-packages/setuptools/__init__.py\", line 153, in setup\n",
      "      return distutils.core.setup(**attrs)\n",
      "    File \"/Users/joel.gongora/opt/anaconda3/envs/drum_corrected/lib/python3.7/distutils/core.py\", line 148, in setup\n",
      "      dist.run_commands()\n",
      "    File \"/Users/joel.gongora/opt/anaconda3/envs/drum_corrected/lib/python3.7/distutils/dist.py\", line 966, in run_commands\n",
      "      self.run_command(cmd)\n",
      "    File \"/Users/joel.gongora/opt/anaconda3/envs/drum_corrected/lib/python3.7/distutils/dist.py\", line 985, in run_command\n",
      "      cmd_obj.run()\n",
      "    File \"/Users/joel.gongora/opt/anaconda3/envs/drum_corrected/lib/python3.7/site-packages/wheel/bdist_wheel.py\", line 326, in run\n",
      "      self.run_command('install')\n",
      "    File \"/Users/joel.gongora/opt/anaconda3/envs/drum_corrected/lib/python3.7/distutils/cmd.py\", line 313, in run_command\n",
      "      self.distribution.run_command(command)\n",
      "    File \"/Users/joel.gongora/opt/anaconda3/envs/drum_corrected/lib/python3.7/distutils/dist.py\", line 985, in run_command\n",
      "      cmd_obj.run()\n",
      "    File \"/private/var/folders/nz/89yd1h313yn8t9lr6lw41zf80000gq/T/pip-install-5i6j2l6o/uwsgi/setup.py\", line 77, in run\n",
      "      conf = uc.uConf(get_profile())\n",
      "    File \"/private/var/folders/nz/89yd1h313yn8t9lr6lw41zf80000gq/T/pip-install-5i6j2l6o/uwsgi/uwsgiconfig.py\", line 755, in __init__\n",
      "      raise Exception(\"you need a C compiler to build uWSGI\")\n",
      "  Exception: you need a C compiler to build uWSGI\n",
      "  ----------------------------------------\u001b[0m\n",
      "\u001b[31m  ERROR: Failed building wheel for uwsgi\u001b[0m\n",
      "\u001b[?25h  Running setup.py clean for uwsgi\n",
      "Failed to build uwsgi\n",
      "Installing collected packages: ruamel.yaml.clib, ruamel.yaml, strictyaml, importlib-metadata, argcomplete, datarobot, julia, pyarrow, Pillow, flask-cors, uwsgi\n",
      "  Attempting uninstall: strictyaml\n",
      "    Found existing installation: strictyaml 1.4.4\n",
      "    Uninstalling strictyaml-1.4.4:\n",
      "      Successfully uninstalled strictyaml-1.4.4\n",
      "  Attempting uninstall: importlib-metadata\n",
      "    Found existing installation: importlib-metadata 2.0.0\n",
      "    Uninstalling importlib-metadata-2.0.0:\n",
      "      Successfully uninstalled importlib-metadata-2.0.0\n",
      "  Attempting uninstall: argcomplete\n",
      "    Found existing installation: argcomplete 1.12.3\n",
      "    Uninstalling argcomplete-1.12.3:\n",
      "      Successfully uninstalled argcomplete-1.12.3\n",
      "  Attempting uninstall: datarobot\n",
      "    Found existing installation: datarobot 2.25.1\n",
      "    Uninstalling datarobot-2.25.1:\n",
      "      Successfully uninstalled datarobot-2.25.1\n",
      "  Attempting uninstall: pyarrow\n",
      "    Found existing installation: pyarrow 5.0.0\n",
      "    Uninstalling pyarrow-5.0.0:\n",
      "      Successfully uninstalled pyarrow-5.0.0\n",
      "  Attempting uninstall: Pillow\n",
      "    Found existing installation: Pillow 8.0.0\n",
      "    Uninstalling Pillow-8.0.0:\n",
      "      Successfully uninstalled Pillow-8.0.0\n",
      "    Running setup.py install for uwsgi ... \u001b[?25lerror\n",
      "\u001b[31m    ERROR: Command errored out with exit status 1:\n",
      "     command: /Users/joel.gongora/opt/anaconda3/envs/drum_corrected/bin/python -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/private/var/folders/nz/89yd1h313yn8t9lr6lw41zf80000gq/T/pip-install-5i6j2l6o/uwsgi/setup.py'\"'\"'; __file__='\"'\"'/private/var/folders/nz/89yd1h313yn8t9lr6lw41zf80000gq/T/pip-install-5i6j2l6o/uwsgi/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record /private/var/folders/nz/89yd1h313yn8t9lr6lw41zf80000gq/T/pip-record-3tkssfi4/install-record.txt --single-version-externally-managed --compile --install-headers /Users/joel.gongora/opt/anaconda3/envs/drum_corrected/include/python3.7m/uwsgi\n",
      "         cwd: /private/var/folders/nz/89yd1h313yn8t9lr6lw41zf80000gq/T/pip-install-5i6j2l6o/uwsgi/\n",
      "    Complete output (29 lines):\n",
      "    /Users/joel.gongora/opt/anaconda3/envs/drum_corrected/lib/python3.7/distutils/dist.py:274: UserWarning: Unknown distribution option: 'descriptions'\n",
      "      warnings.warn(msg)\n",
      "    running install\n",
      "    using profile: buildconf/default.ini\n",
      "    detected include path: ['/usr/local/include', '/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/lib/clang/12.0.5/include', '/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX.sdk/usr/include', '/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include', '/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX.sdk/System/Library/Frameworks']\n",
      "    Traceback (most recent call last):\n",
      "      File \"/private/var/folders/nz/89yd1h313yn8t9lr6lw41zf80000gq/T/pip-install-5i6j2l6o/uwsgi/uwsgiconfig.py\", line 747, in __init__\n",
      "        gcc_version_components = gcc_version.split('.')\n",
      "    AttributeError: 'NoneType' object has no attribute 'split'\n",
      "    \n",
      "    During handling of the above exception, another exception occurred:\n",
      "    \n",
      "    Traceback (most recent call last):\n",
      "      File \"<string>\", line 1, in <module>\n",
      "      File \"/private/var/folders/nz/89yd1h313yn8t9lr6lw41zf80000gq/T/pip-install-5i6j2l6o/uwsgi/setup.py\", line 140, in <module>\n",
      "        'Programming Language :: Python :: 3.8',\n",
      "      File \"/Users/joel.gongora/opt/anaconda3/envs/drum_corrected/lib/python3.7/site-packages/setuptools/__init__.py\", line 153, in setup\n",
      "        return distutils.core.setup(**attrs)\n",
      "      File \"/Users/joel.gongora/opt/anaconda3/envs/drum_corrected/lib/python3.7/distutils/core.py\", line 148, in setup\n",
      "        dist.run_commands()\n",
      "      File \"/Users/joel.gongora/opt/anaconda3/envs/drum_corrected/lib/python3.7/distutils/dist.py\", line 966, in run_commands\n",
      "        self.run_command(cmd)\n",
      "      File \"/Users/joel.gongora/opt/anaconda3/envs/drum_corrected/lib/python3.7/distutils/dist.py\", line 985, in run_command\n",
      "        cmd_obj.run()\n",
      "      File \"/private/var/folders/nz/89yd1h313yn8t9lr6lw41zf80000gq/T/pip-install-5i6j2l6o/uwsgi/setup.py\", line 77, in run\n",
      "        conf = uc.uConf(get_profile())\n",
      "      File \"/private/var/folders/nz/89yd1h313yn8t9lr6lw41zf80000gq/T/pip-install-5i6j2l6o/uwsgi/uwsgiconfig.py\", line 755, in __init__\n",
      "        raise Exception(\"you need a C compiler to build uWSGI\")\n",
      "    Exception: you need a C compiler to build uWSGI\n",
      "    ----------------------------------------\u001b[0m\n",
      "\u001b[31mERROR: Command errored out with exit status 1: /Users/joel.gongora/opt/anaconda3/envs/drum_corrected/bin/python -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/private/var/folders/nz/89yd1h313yn8t9lr6lw41zf80000gq/T/pip-install-5i6j2l6o/uwsgi/setup.py'\"'\"'; __file__='\"'\"'/private/var/folders/nz/89yd1h313yn8t9lr6lw41zf80000gq/T/pip-install-5i6j2l6o/uwsgi/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record /private/var/folders/nz/89yd1h313yn8t9lr6lw41zf80000gq/T/pip-record-3tkssfi4/install-record.txt --single-version-externally-managed --compile --install-headers /Users/joel.gongora/opt/anaconda3/envs/drum_corrected/include/python3.7m/uwsgi Check the logs for full command output.\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "#In case I need to update datarobot-drum\n",
    "!pip install datarobot-drum --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/readmissions_train.csv')\n",
    "test = pd.read_csv('../data/readmissions_test.csv')\n",
    "\n",
    "X = train.drop(['id', 'readmitted'],axis=1)\n",
    "X.drop(['diag_2_desc', 'diag_3_desc'],axis=1,inplace=True)\n",
    "test.drop(['id', 'diag_2_desc', 'diag_3_desc'],axis=1,inplace=True)\n",
    "y = train.pop('readmitted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Preprocessing step per type of column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocessing for numerical features\n",
    "numeric_features = list(X.select_dtypes('int64').columns)\n",
    "for c in numeric_features:\n",
    "    X[c] = X[c].fillna(0)\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "#Preprocessing for categorical features\n",
    "categorical_features = list(X.select_dtypes('object').columns)\n",
    "for c in categorical_features:\n",
    "    X[c] = X[c].fillna('missing')\n",
    "    \n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('OneHotEncoder', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "#Preprocessor with all of the steps\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the Preprocessing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full preprocessing pipeline\n",
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor)])\n",
    "\n",
    "#Train the model-Pipeline\n",
    "pipeline.fit(X,y)\n",
    "\n",
    "#Preprocess x\n",
    "preprocessed = pipeline.transform(X)\n",
    "\n",
    "#I could also train the model with the sparse matrix. I transform it to padnas because the hook function in custom.py expected a pandas dataframe to be used for scoring.\n",
    "preprocessed = pd.DataFrame.sparse.from_spmatrix(preprocessed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train XGboost Classifier\n",
    "Normally, the XGboost classifier could be part of the final scikit-learn pipeline. I am opting to keep them separate in order to create a more complicated example with different pkl files for preprocessing and scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joel.gongora/opt/anaconda3/envs/drum_corrected/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:38:26] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=0.2,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.02, max_delta_step=0, max_depth=10,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=300, n_jobs=8, num_parallel_tree=1, random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = XGBClassifier(colsample_bylevel=0.2, max_depth= 10, learning_rate = 0.02, n_estimators=300)\n",
    "model.fit(preprocessed, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/joel.gongora/DataRobot/repos/FORKED/custom-models/custom_inference/python/readmissions/Readmission_level_3'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['custom_model/model.pkl']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(pipeline,'custom_model/preprocessing.pkl')\n",
    "joblib.dump(model, 'custom_model/model.pkl') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Custom Model files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "joblib.dump(pipeline,'custom_model/preprocessing.pkl')\n",
    "joblib.dump(model, 'custom_model/model.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/joel.gongora/opt/anaconda3/envs/drum_corrected/bin/drum\", line 6, in <module>\n",
      "    main()\n",
      "  File \"/Users/joel.gongora/opt/anaconda3/envs/drum_corrected/lib/python3.7/site-packages/datarobot_drum/drum/main.py\", line 168, in main\n",
      "    CMRunner(runtime).run()\n",
      "  File \"/Users/joel.gongora/opt/anaconda3/envs/drum_corrected/lib/python3.7/site-packages/datarobot_drum/drum/drum.py\", line 457, in run\n",
      "    self._run_fit_or_predictions_pipelines_in_mlpiper()\n",
      "  File \"/Users/joel.gongora/opt/anaconda3/envs/drum_corrected/lib/python3.7/site-packages/datarobot_drum/drum/drum.py\", line 753, in _run_fit_or_predictions_pipelines_in_mlpiper\n",
      "    _pipeline_executor.run_pipeline(cleanup=False)\n",
      "  File \"/Users/joel.gongora/opt/anaconda3/envs/drum_corrected/lib/python3.7/site-packages/mlpiper/pipeline/executor.py\", line 261, in run_pipeline\n",
      "    self._run_pipeline()\n",
      "  File \"/Users/joel.gongora/opt/anaconda3/envs/drum_corrected/lib/python3.7/site-packages/mlpiper/pipeline/executor.py\", line 251, in _run_pipeline\n",
      "    self._dag.run_connected_pipeline(self._ml_engine)\n",
      "  File \"/Users/joel.gongora/opt/anaconda3/envs/drum_corrected/lib/python3.7/site-packages/mlpiper/pipeline/dag.py\", line 137, in run_connected_pipeline\n",
      "    data_objs = dag_node.component_runner.run(parent_data_objs)\n",
      "  File \"/Users/joel.gongora/opt/anaconda3/envs/drum_corrected/lib/python3.7/site-packages/mlpiper/pipeline/component_runner/python_connected_component_runner.py\", line 14, in run\n",
      "    data_objs = self._dag_node.main_cls().materialize(parent_data_objs)\n",
      "  File \"/Users/joel.gongora/opt/anaconda3/envs/drum_corrected/lib/python3.7/site-packages/mlpiper/components/connectable_component.py\", line 11, in materialize\n",
      "    return self._materialize(parent_data_objs, self._ml_engine.user_data)\n",
      "  File \"/Users/joel.gongora/opt/anaconda3/envs/drum_corrected/lib/python3.7/site-packages/datarobot_drum/resource/components/Python/generic_predictor/generic_predictor.py\", line 114, in _materialize\n",
      "    predictions = self._predictor.predict(binary_data=binary_data, mimetype=mimetype)\n",
      "  File \"/Users/joel.gongora/opt/anaconda3/envs/drum_corrected/lib/python3.7/site-packages/datarobot_drum/drum/language_predictors/base_language_predictor.py\", line 111, in predict\n",
      "    predictions = self._predict(**kwargs)\n",
      "  File \"/Users/joel.gongora/opt/anaconda3/envs/drum_corrected/lib/python3.7/site-packages/datarobot_drum/drum/language_predictors/python_predictor/python_predictor.py\", line 57, in _predict\n",
      "    predictions = self._model_adapter.predict(model=self._model, **kwargs)\n",
      "  File \"/Users/joel.gongora/opt/anaconda3/envs/drum_corrected/lib/python3.7/site-packages/datarobot_drum/drum/model_adapter.py\", line 449, in predict\n",
      "    data = self.preprocess(model, **kwargs)\n",
      "  File \"/Users/joel.gongora/opt/anaconda3/envs/drum_corrected/lib/python3.7/site-packages/datarobot_drum/drum/model_adapter.py\", line 355, in preprocess\n",
      "    ).with_traceback(sys.exc_info()[2]) from None\n",
      "  File \"/Users/joel.gongora/opt/anaconda3/envs/drum_corrected/lib/python3.7/site-packages/datarobot_drum/drum/model_adapter.py\", line 350, in preprocess\n",
      "    output_data = self._custom_hooks[CustomHooks.TRANSFORM](data, model)\n",
      "  File \"/Users/joel.gongora/DataRobot/repos/FORKED/custom-models/custom_inference/python/readmissions/Readmission_level_3/custom_model/custom.py\", line 133, in transform\n",
      "    preprocessed = pipeline.transform(data)\n",
      "  File \"/Users/joel.gongora/opt/anaconda3/envs/drum_corrected/lib/python3.7/site-packages/sklearn/pipeline.py\", line 560, in _transform\n",
      "    Xt = transform.transform(Xt)\n",
      "  File \"/Users/joel.gongora/opt/anaconda3/envs/drum_corrected/lib/python3.7/site-packages/sklearn/compose/_column_transformer.py\", line 556, in transform\n",
      "    self._check_n_features(X, reset=False)\n",
      "  File \"/Users/joel.gongora/opt/anaconda3/envs/drum_corrected/lib/python3.7/site-packages/sklearn/base.py\", line 366, in _check_n_features\n",
      "    f\"X has {n_features} features, but {self.__class__.__name__} \"\n",
      "ValueError: Model transform hook failed to transform dataset: X has 45 features, but ColumnTransformer is expecting 48 features as input.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/joel.gongora/opt/anaconda3/envs/drum_corrected/bin/drum\", line 6, in <module>\n",
      "    main()\n",
      "  File \"/Users/joel.gongora/opt/anaconda3/envs/drum_corrected/lib/python3.7/site-packages/datarobot_drum/drum/main.py\", line 168, in main\n",
      "    CMRunner(runtime).run()\n",
      "  File \"/Users/joel.gongora/opt/anaconda3/envs/drum_corrected/lib/python3.7/site-packages/datarobot_drum/drum/drum.py\", line 457, in run\n",
      "    self._run_fit_or_predictions_pipelines_in_mlpiper()\n",
      "  File \"/Users/joel.gongora/opt/anaconda3/envs/drum_corrected/lib/python3.7/site-packages/datarobot_drum/drum/drum.py\", line 753, in _run_fit_or_predictions_pipelines_in_mlpiper\n",
      "    _pipeline_executor.run_pipeline(cleanup=False)\n",
      "  File \"/Users/joel.gongora/opt/anaconda3/envs/drum_corrected/lib/python3.7/site-packages/mlpiper/pipeline/executor.py\", line 261, in run_pipeline\n",
      "    self._run_pipeline()\n",
      "  File \"/Users/joel.gongora/opt/anaconda3/envs/drum_corrected/lib/python3.7/site-packages/mlpiper/pipeline/executor.py\", line 251, in _run_pipeline\n",
      "    self._dag.run_connected_pipeline(self._ml_engine)\n",
      "  File \"/Users/joel.gongora/opt/anaconda3/envs/drum_corrected/lib/python3.7/site-packages/mlpiper/pipeline/dag.py\", line 137, in run_connected_pipeline\n",
      "    data_objs = dag_node.component_runner.run(parent_data_objs)\n",
      "  File \"/Users/joel.gongora/opt/anaconda3/envs/drum_corrected/lib/python3.7/site-packages/mlpiper/pipeline/component_runner/python_connected_component_runner.py\", line 14, in run\n",
      "    data_objs = self._dag_node.main_cls().materialize(parent_data_objs)\n",
      "  File \"/Users/joel.gongora/opt/anaconda3/envs/drum_corrected/lib/python3.7/site-packages/mlpiper/components/connectable_component.py\", line 11, in materialize\n",
      "    return self._materialize(parent_data_objs, self._ml_engine.user_data)\n",
      "  File \"/Users/joel.gongora/opt/anaconda3/envs/drum_corrected/lib/python3.7/site-packages/datarobot_drum/resource/components/Python/generic_predictor/generic_predictor.py\", line 114, in _materialize\n",
      "    predictions = self._predictor.predict(binary_data=binary_data, mimetype=mimetype)\n",
      "  File \"/Users/joel.gongora/opt/anaconda3/envs/drum_corrected/lib/python3.7/site-packages/datarobot_drum/drum/language_predictors/base_language_predictor.py\", line 111, in predict\n",
      "    predictions = self._predict(**kwargs)\n",
      "  File \"/Users/joel.gongora/opt/anaconda3/envs/drum_corrected/lib/python3.7/site-packages/datarobot_drum/drum/language_predictors/python_predictor/python_predictor.py\", line 57, in _predict\n",
      "    predictions = self._model_adapter.predict(model=self._model, **kwargs)\n",
      "  File \"/Users/joel.gongora/opt/anaconda3/envs/drum_corrected/lib/python3.7/site-packages/datarobot_drum/drum/model_adapter.py\", line 449, in predict\n",
      "    data = self.preprocess(model, **kwargs)\n",
      "  File \"/Users/joel.gongora/opt/anaconda3/envs/drum_corrected/lib/python3.7/site-packages/datarobot_drum/drum/model_adapter.py\", line 355, in preprocess\n",
      "    ).with_traceback(sys.exc_info()[2]) from None\n",
      "  File \"/Users/joel.gongora/opt/anaconda3/envs/drum_corrected/lib/python3.7/site-packages/datarobot_drum/drum/model_adapter.py\", line 350, in preprocess\n",
      "    output_data = self._custom_hooks[CustomHooks.TRANSFORM](data, model)\n",
      "  File \"/Users/joel.gongora/DataRobot/repos/FORKED/custom-models/custom_inference/python/readmissions/Readmission_level_3/custom_model/custom.py\", line 133, in transform\n",
      "    preprocessed = pipeline.transform(data)\n",
      "  File \"/Users/joel.gongora/opt/anaconda3/envs/drum_corrected/lib/python3.7/site-packages/sklearn/pipeline.py\", line 560, in _transform\n",
      "    Xt = transform.transform(Xt)\n",
      "  File \"/Users/joel.gongora/opt/anaconda3/envs/drum_corrected/lib/python3.7/site-packages/sklearn/compose/_column_transformer.py\", line 556, in transform\n",
      "    self._check_n_features(X, reset=False)\n",
      "  File \"/Users/joel.gongora/opt/anaconda3/envs/drum_corrected/lib/python3.7/site-packages/sklearn/base.py\", line 366, in _check_n_features\n",
      "    f\"X has {n_features} features, but {self.__class__.__name__} \"\n",
      "ValueError: Model transform hook failed to transform dataset: X has 45 features, but ColumnTransformer is expecting 48 features as input.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/joel.gongora/opt/anaconda3/envs/drum_corrected/bin/drum\", line 6, in <module>\n",
      "    main()\n",
      "  File \"/Users/joel.gongora/opt/anaconda3/envs/drum_corrected/lib/python3.7/site-packages/datarobot_drum/drum/main.py\", line 168, in main\n",
      "    CMRunner(runtime).run()\n",
      "  File \"/Users/joel.gongora/opt/anaconda3/envs/drum_corrected/lib/python3.7/site-packages/datarobot_drum/drum/drum.py\", line 457, in run\n",
      "    self._run_fit_or_predictions_pipelines_in_mlpiper()\n",
      "  File \"/Users/joel.gongora/opt/anaconda3/envs/drum_corrected/lib/python3.7/site-packages/datarobot_drum/drum/drum.py\", line 753, in _run_fit_or_predictions_pipelines_in_mlpiper\n",
      "    _pipeline_executor.run_pipeline(cleanup=False)\n",
      "  File \"/Users/joel.gongora/opt/anaconda3/envs/drum_corrected/lib/python3.7/site-packages/mlpiper/pipeline/executor.py\", line 261, in run_pipeline\n",
      "    self._run_pipeline()\n",
      "  File \"/Users/joel.gongora/opt/anaconda3/envs/drum_corrected/lib/python3.7/site-packages/mlpiper/pipeline/executor.py\", line 251, in _run_pipeline\n",
      "    self._dag.run_connected_pipeline(self._ml_engine)\n",
      "  File \"/Users/joel.gongora/opt/anaconda3/envs/drum_corrected/lib/python3.7/site-packages/mlpiper/pipeline/dag.py\", line 137, in run_connected_pipeline\n",
      "    data_objs = dag_node.component_runner.run(parent_data_objs)\n",
      "  File \"/Users/joel.gongora/opt/anaconda3/envs/drum_corrected/lib/python3.7/site-packages/mlpiper/pipeline/component_runner/python_connected_component_runner.py\", line 14, in run\n",
      "    data_objs = self._dag_node.main_cls().materialize(parent_data_objs)\n",
      "  File \"/Users/joel.gongora/opt/anaconda3/envs/drum_corrected/lib/python3.7/site-packages/mlpiper/components/connectable_component.py\", line 11, in materialize\n",
      "    return self._materialize(parent_data_objs, self._ml_engine.user_data)\n",
      "  File \"/Users/joel.gongora/opt/anaconda3/envs/drum_corrected/lib/python3.7/site-packages/datarobot_drum/resource/components/Python/generic_predictor/generic_predictor.py\", line 114, in _materialize\n",
      "    predictions = self._predictor.predict(binary_data=binary_data, mimetype=mimetype)\n",
      "  File \"/Users/joel.gongora/opt/anaconda3/envs/drum_corrected/lib/python3.7/site-packages/datarobot_drum/drum/language_predictors/base_language_predictor.py\", line 111, in predict\n",
      "    predictions = self._predict(**kwargs)\n",
      "  File \"/Users/joel.gongora/opt/anaconda3/envs/drum_corrected/lib/python3.7/site-packages/datarobot_drum/drum/language_predictors/python_predictor/python_predictor.py\", line 57, in _predict\n",
      "    predictions = self._model_adapter.predict(model=self._model, **kwargs)\n",
      "  File \"/Users/joel.gongora/opt/anaconda3/envs/drum_corrected/lib/python3.7/site-packages/datarobot_drum/drum/model_adapter.py\", line 449, in predict\n",
      "    data = self.preprocess(model, **kwargs)\n",
      "  File \"/Users/joel.gongora/opt/anaconda3/envs/drum_corrected/lib/python3.7/site-packages/datarobot_drum/drum/model_adapter.py\", line 355, in preprocess\n",
      "    ).with_traceback(sys.exc_info()[2]) from None\n",
      "  File \"/Users/joel.gongora/opt/anaconda3/envs/drum_corrected/lib/python3.7/site-packages/datarobot_drum/drum/model_adapter.py\", line 350, in preprocess\n",
      "    output_data = self._custom_hooks[CustomHooks.TRANSFORM](data, model)\n",
      "  File \"/Users/joel.gongora/DataRobot/repos/FORKED/custom-models/custom_inference/python/readmissions/Readmission_level_3/custom_model/custom.py\", line 133, in transform\n",
      "    preprocessed = pipeline.transform(data)\n",
      "  File \"/Users/joel.gongora/opt/anaconda3/envs/drum_corrected/lib/python3.7/site-packages/sklearn/pipeline.py\", line 560, in _transform\n",
      "    Xt = transform.transform(Xt)\n",
      "  File \"/Users/joel.gongora/opt/anaconda3/envs/drum_corrected/lib/python3.7/site-packages/sklearn/compose/_column_transformer.py\", line 556, in transform\n",
      "    self._check_n_features(X, reset=False)\n",
      "  File \"/Users/joel.gongora/opt/anaconda3/envs/drum_corrected/lib/python3.7/site-packages/sklearn/base.py\", line 366, in _check_n_features\n",
      "    f\"X has {n_features} features, but {self.__class__.__name__} \"\n",
      "ValueError: Model transform hook failed to transform dataset: X has 45 features, but ColumnTransformer is expecting 48 features as input.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/joel.gongora/opt/anaconda3/envs/drum_corrected/bin/drum\", line 6, in <module>\n",
      "    main()\n",
      "  File \"/Users/joel.gongora/opt/anaconda3/envs/drum_corrected/lib/python3.7/site-packages/datarobot_drum/drum/main.py\", line 168, in main\n",
      "    CMRunner(runtime).run()\n",
      "  File \"/Users/joel.gongora/opt/anaconda3/envs/drum_corrected/lib/python3.7/site-packages/datarobot_drum/drum/drum.py\", line 457, in run\n",
      "    self._run_fit_or_predictions_pipelines_in_mlpiper()\n",
      "  File \"/Users/joel.gongora/opt/anaconda3/envs/drum_corrected/lib/python3.7/site-packages/datarobot_drum/drum/drum.py\", line 753, in _run_fit_or_predictions_pipelines_in_mlpiper\n",
      "    _pipeline_executor.run_pipeline(cleanup=False)\n",
      "  File \"/Users/joel.gongora/opt/anaconda3/envs/drum_corrected/lib/python3.7/site-packages/mlpiper/pipeline/executor.py\", line 261, in run_pipeline\n",
      "    self._run_pipeline()\n",
      "  File \"/Users/joel.gongora/opt/anaconda3/envs/drum_corrected/lib/python3.7/site-packages/mlpiper/pipeline/executor.py\", line 251, in _run_pipeline\n",
      "    self._dag.run_connected_pipeline(self._ml_engine)\n",
      "  File \"/Users/joel.gongora/opt/anaconda3/envs/drum_corrected/lib/python3.7/site-packages/mlpiper/pipeline/dag.py\", line 137, in run_connected_pipeline\n",
      "    data_objs = dag_node.component_runner.run(parent_data_objs)\n",
      "  File \"/Users/joel.gongora/opt/anaconda3/envs/drum_corrected/lib/python3.7/site-packages/mlpiper/pipeline/component_runner/python_connected_component_runner.py\", line 14, in run\n",
      "    data_objs = self._dag_node.main_cls().materialize(parent_data_objs)\n",
      "  File \"/Users/joel.gongora/opt/anaconda3/envs/drum_corrected/lib/python3.7/site-packages/mlpiper/components/connectable_component.py\", line 11, in materialize\n",
      "    return self._materialize(parent_data_objs, self._ml_engine.user_data)\n",
      "  File \"/Users/joel.gongora/opt/anaconda3/envs/drum_corrected/lib/python3.7/site-packages/datarobot_drum/resource/components/Python/generic_predictor/generic_predictor.py\", line 114, in _materialize\n",
      "    predictions = self._predictor.predict(binary_data=binary_data, mimetype=mimetype)\n",
      "  File \"/Users/joel.gongora/opt/anaconda3/envs/drum_corrected/lib/python3.7/site-packages/datarobot_drum/drum/language_predictors/base_language_predictor.py\", line 111, in predict\n",
      "    predictions = self._predict(**kwargs)\n",
      "  File \"/Users/joel.gongora/opt/anaconda3/envs/drum_corrected/lib/python3.7/site-packages/datarobot_drum/drum/language_predictors/python_predictor/python_predictor.py\", line 57, in _predict\n",
      "    predictions = self._model_adapter.predict(model=self._model, **kwargs)\n",
      "  File \"/Users/joel.gongora/opt/anaconda3/envs/drum_corrected/lib/python3.7/site-packages/datarobot_drum/drum/model_adapter.py\", line 449, in predict\n",
      "    data = self.preprocess(model, **kwargs)\n",
      "  File \"/Users/joel.gongora/opt/anaconda3/envs/drum_corrected/lib/python3.7/site-packages/datarobot_drum/drum/model_adapter.py\", line 355, in preprocess\n",
      "    ).with_traceback(sys.exc_info()[2]) from None\n",
      "  File \"/Users/joel.gongora/opt/anaconda3/envs/drum_corrected/lib/python3.7/site-packages/datarobot_drum/drum/model_adapter.py\", line 350, in preprocess\n",
      "    output_data = self._custom_hooks[CustomHooks.TRANSFORM](data, model)\n",
      "  File \"/Users/joel.gongora/DataRobot/repos/FORKED/custom-models/custom_inference/python/readmissions/Readmission_level_3/custom_model/custom.py\", line 133, in transform\n",
      "    preprocessed = pipeline.transform(data)\n",
      "  File \"/Users/joel.gongora/opt/anaconda3/envs/drum_corrected/lib/python3.7/site-packages/sklearn/pipeline.py\", line 560, in _transform\n",
      "    Xt = transform.transform(Xt)\n",
      "  File \"/Users/joel.gongora/opt/anaconda3/envs/drum_corrected/lib/python3.7/site-packages/sklearn/compose/_column_transformer.py\", line 556, in transform\n",
      "    self._check_n_features(X, reset=False)\n",
      "  File \"/Users/joel.gongora/opt/anaconda3/envs/drum_corrected/lib/python3.7/site-packages/sklearn/base.py\", line 366, in _check_n_features\n",
      "    f\"X has {n_features} features, but {self.__class__.__name__} \"\n",
      "ValueError: Model transform hook failed to transform dataset: X has 45 features, but ColumnTransformer is expecting 48 features as input.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/joel.gongora/opt/anaconda3/envs/drum_corrected/bin/drum\", line 6, in <module>\n",
      "    main()\n",
      "  File \"/Users/joel.gongora/opt/anaconda3/envs/drum_corrected/lib/python3.7/site-packages/datarobot_drum/drum/main.py\", line 168, in main\n",
      "    CMRunner(runtime).run()\n",
      "  File \"/Users/joel.gongora/opt/anaconda3/envs/drum_corrected/lib/python3.7/site-packages/datarobot_drum/drum/drum.py\", line 457, in run\n",
      "    self._run_fit_or_predictions_pipelines_in_mlpiper()\n",
      "  File \"/Users/joel.gongora/opt/anaconda3/envs/drum_corrected/lib/python3.7/site-packages/datarobot_drum/drum/drum.py\", line 753, in _run_fit_or_predictions_pipelines_in_mlpiper\n",
      "    _pipeline_executor.run_pipeline(cleanup=False)\n",
      "  File \"/Users/joel.gongora/opt/anaconda3/envs/drum_corrected/lib/python3.7/site-packages/mlpiper/pipeline/executor.py\", line 261, in run_pipeline\n",
      "    self._run_pipeline()\n",
      "  File \"/Users/joel.gongora/opt/anaconda3/envs/drum_corrected/lib/python3.7/site-packages/mlpiper/pipeline/executor.py\", line 251, in _run_pipeline\n",
      "    self._dag.run_connected_pipeline(self._ml_engine)\n",
      "  File \"/Users/joel.gongora/opt/anaconda3/envs/drum_corrected/lib/python3.7/site-packages/mlpiper/pipeline/dag.py\", line 137, in run_connected_pipeline\n",
      "    data_objs = dag_node.component_runner.run(parent_data_objs)\n",
      "  File \"/Users/joel.gongora/opt/anaconda3/envs/drum_corrected/lib/python3.7/site-packages/mlpiper/pipeline/component_runner/python_connected_component_runner.py\", line 14, in run\n",
      "    data_objs = self._dag_node.main_cls().materialize(parent_data_objs)\n",
      "  File \"/Users/joel.gongora/opt/anaconda3/envs/drum_corrected/lib/python3.7/site-packages/mlpiper/components/connectable_component.py\", line 11, in materialize\n",
      "    return self._materialize(parent_data_objs, self._ml_engine.user_data)\n",
      "  File \"/Users/joel.gongora/opt/anaconda3/envs/drum_corrected/lib/python3.7/site-packages/datarobot_drum/resource/components/Python/generic_predictor/generic_predictor.py\", line 114, in _materialize\n",
      "    predictions = self._predictor.predict(binary_data=binary_data, mimetype=mimetype)\n",
      "  File \"/Users/joel.gongora/opt/anaconda3/envs/drum_corrected/lib/python3.7/site-packages/datarobot_drum/drum/language_predictors/base_language_predictor.py\", line 111, in predict\n",
      "    predictions = self._predict(**kwargs)\n",
      "  File \"/Users/joel.gongora/opt/anaconda3/envs/drum_corrected/lib/python3.7/site-packages/datarobot_drum/drum/language_predictors/python_predictor/python_predictor.py\", line 57, in _predict\n",
      "    predictions = self._model_adapter.predict(model=self._model, **kwargs)\n",
      "  File \"/Users/joel.gongora/opt/anaconda3/envs/drum_corrected/lib/python3.7/site-packages/datarobot_drum/drum/model_adapter.py\", line 449, in predict\n",
      "    data = self.preprocess(model, **kwargs)\n",
      "  File \"/Users/joel.gongora/opt/anaconda3/envs/drum_corrected/lib/python3.7/site-packages/datarobot_drum/drum/model_adapter.py\", line 355, in preprocess\n",
      "    ).with_traceback(sys.exc_info()[2]) from None\n",
      "  File \"/Users/joel.gongora/opt/anaconda3/envs/drum_corrected/lib/python3.7/site-packages/datarobot_drum/drum/model_adapter.py\", line 350, in preprocess\n",
      "    output_data = self._custom_hooks[CustomHooks.TRANSFORM](data, model)\n",
      "  File \"/Users/joel.gongora/DataRobot/repos/FORKED/custom-models/custom_inference/python/readmissions/Readmission_level_3/custom_model/custom.py\", line 133, in transform\n",
      "    preprocessed = pipeline.transform(data)\n",
      "  File \"/Users/joel.gongora/opt/anaconda3/envs/drum_corrected/lib/python3.7/site-packages/sklearn/pipeline.py\", line 560, in _transform\n",
      "    Xt = transform.transform(Xt)\n",
      "  File \"/Users/joel.gongora/opt/anaconda3/envs/drum_corrected/lib/python3.7/site-packages/sklearn/compose/_column_transformer.py\", line 556, in transform\n",
      "    self._check_n_features(X, reset=False)\n",
      "  File \"/Users/joel.gongora/opt/anaconda3/envs/drum_corrected/lib/python3.7/site-packages/sklearn/base.py\", line 366, in _check_n_features\n",
      "    f\"X has {n_features} features, but {self.__class__.__name__} \"\n",
      "ValueError: Model transform hook failed to transform dataset: X has 45 features, but ColumnTransformer is expecting 48 features as input.\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/joel.gongora/opt/anaconda3/envs/drum_corrected/bin/drum\", line 5, in <module>\n",
      "\n",
      "Ctrl+C pressed, aborting drum\n",
      "    from datarobot_drum.drum.main import main\n",
      "  File \"/Users/joel.gongora/opt/anaconda3/envs/drum_corrected/lib/python3.7/site-packages/datarobot_drum/drum/main.py\", line 36, in <module>\n",
      "    from datarobot_drum.drum.args_parser import CMRunnerArgsRegistry\n",
      "  File \"/Users/joel.gongora/opt/anaconda3/envs/drum_corrected/lib/python3.7/site-packages/datarobot_drum/drum/args_parser.py\", line 4, in <module>\n",
      "    from datarobot_drum.drum.push import PUSH_HELP_TEXT\n",
      "  File \"/Users/joel.gongora/opt/anaconda3/envs/drum_corrected/lib/python3.7/site-packages/datarobot_drum/drum/push.py\", line 5, in <module>\n",
      "    import datarobot as dr_client\n",
      "  File \"/Users/joel.gongora/opt/anaconda3/envs/drum_corrected/lib/python3.7/site-packages/datarobot/__init__.py\", line 4, in <module>\n",
      "    from .client import Client\n",
      "  File \"/Users/joel.gongora/opt/anaconda3/envs/drum_corrected/lib/python3.7/site-packages/datarobot/client.py\", line 2, in <module>\n",
      "    import logging\n",
      "  File \"/Users/joel.gongora/opt/anaconda3/envs/drum_corrected/lib/python3.7/logging/__init__.py\", line 26, in <module>\n",
      "    import sys, os, time, io, traceback, warnings, weakref, collections.abc\n",
      "  File \"/Users/joel.gongora/opt/anaconda3/envs/drum_corrected/lib/python3.7/weakref.py\", line 90, in <module>\n",
      "    class WeakValueDictionary(_collections_abc.MutableMapping):\n",
      "  File \"/Users/joel.gongora/opt/anaconda3/envs/drum_corrected/lib/python3.7/abc.py\", line 126, in __new__\n",
      "    cls = super().__new__(mcls, name, bases, namespace, **kwargs)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!drum validation --code-dir ./custom_model --input ../data/readmissions_test.csv --target-type binary --positive-class-label True --negative-class-label False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate model can work as `Custom Training Model`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/joel.gongora/opt/anaconda3/envs/drum_corrected/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "[16:35:57] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Files were overwritten: {'/var/folders/nz/89yd1h313yn8t9lr6lw41zf80000gq/T/tmpwj6xao3u/model.pkl', '/var/folders/nz/89yd1h313yn8t9lr6lw41zf80000gq/T/tmpwj6xao3u/preprocessing.pkl'}\n",
      "\n",
      "Failure in predict server: {\"message\":\"ERROR: Model transform hook failed to transform dataset: X has 45 features, but ColumnTransformer is expecting 48 features as input.\"}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!drum fit --code-dir ./custom_model --input ../data/readmissions_train.csv --target-type binary --target readmitted --positive-class-label True --negative-class-label False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
