{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/datarobot-community/custom-models/blob/master/custom_inference/python/boston_housing/Main_Script.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VLxOyJ2xMrlL"
   },
   "source": [
    "# DRUM - Automated Model Serving Made Easy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_OUbruxUMrlM"
   },
   "source": [
    " We'll get our hands dirty by \n",
    "\n",
    "* Building a simple regression model using Scikit\n",
    "* Using DRUM for Batch Scoring\n",
    "* Using DRUM to get a REST API endpoint\n",
    "* Showing a simple example app connected to the REST API\n",
    "* Reviewing support for various model frameworks (e.g., H2O, Keras, XGBoost, and DataRobot)\n",
    "* Monitoring with the MLOps agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ykjnP6-ZMrlM"
   },
   "source": [
    "## Build a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-IDgpv8NMs7r",
    "outputId": "b4c5d2a3-ed31-4384-d049-607713ff7942"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'mlops-examples'...\n",
      "remote: Enumerating objects: 245, done.\u001b[K\n",
      "remote: Counting objects: 100% (245/245), done.\u001b[K\n",
      "remote: Compressing objects: 100% (157/157), done.\u001b[K\n",
      "remote: Total 245 (delta 96), reused 229 (delta 80), pack-reused 0\u001b[K\n",
      "Receiving objects: 100% (245/245), 18.57 MiB | 40.45 MiB/s, done.\n",
      "Resolving deltas: 100% (96/96), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/datarobot-community/mlops-examples.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x86AAdVeMjl6",
    "outputId": "a7a54c71-c0eb-478a-997d-010fa0bd8347"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     |████████████████████████████████| 276kB 8.8MB/s \n",
      "\u001b[K     |████████████████████████████████| 8.7MB 8.9MB/s \n",
      "\u001b[K     |████████████████████████████████| 276kB 54.7MB/s \n",
      "\u001b[K     |████████████████████████████████| 148.9MB 53kB/s \n",
      "\u001b[K     |████████████████████████████████| 61kB 10.0MB/s \n",
      "\u001b[K     |████████████████████████████████| 204kB 57.3MB/s \n",
      "\u001b[K     |████████████████████████████████| 788kB 51.4MB/s \n",
      "\u001b[K     |████████████████████████████████| 153kB 55.5MB/s \n",
      "\u001b[K     |████████████████████████████████| 51kB 7.1MB/s \n",
      "\u001b[K     |████████████████████████████████| 808kB 51.4MB/s \n",
      "\u001b[K     |████████████████████████████████| 204kB 52.4MB/s \n",
      "\u001b[K     |████████████████████████████████| 112kB 57.2MB/s \n",
      "\u001b[K     |████████████████████████████████| 552kB 58.8MB/s \n",
      "\u001b[?25h  Building wheel for PyYAML (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Building wheel for memory-profiler (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Building wheel for progress (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Building wheel for strictyaml (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Building wheel for uwsgi (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -r /content/mlops-examples/custom_inference/python/boston_housing/colab-requirements.txt -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "vAkNyQLWMrlN"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import pickle\n",
    "import datetime\n",
    "\n",
    "## load data\n",
    "\n",
    "df = pd.read_csv(\n",
    "    '/content/mlops-examples/custom_inference/python/boston_housing/data/boston_housing.csv'\n",
    "    )\n",
    "df.head()\n",
    "\n",
    "## set features and target\n",
    "\n",
    "X = df.drop('MEDV', axis=1)\n",
    "y = df['MEDV']\n",
    "\n",
    "## train the model\n",
    "rf = RandomForestRegressor(n_estimators = 20)\n",
    "rf.fit(X,y)\n",
    "\n",
    "## serialize the model\n",
    "\n",
    "with open('/content/mlops-examples/custom_inference/python/boston_housing/src/custom_model/rf.pkl', 'wb') as pkl:\n",
    "    pickle.dump(rf, pkl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DKi7ywP8L192"
   },
   "source": [
    "# Testing\n",
    "\n",
    "You can test how the model performs and get its latency times and memory usage.\n",
    "In this mode, the model is started with a prediction server. Different request combinations are submitted to it. After it completes, it returns a report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FM60vZNHL1cu",
    "outputId": "7e88b64a-bd76-4a48-93b5-b43289962fb7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing test data...\n",
      "\n",
      "\n",
      "\n",
      "Running test case: 72 bytes - 1 samples, 100 iterations\n",
      "Running test case: 0.1MB - 1449 samples, 50 iterations\n",
      "Running test case: 10MB - 144964 samples, 5 iterations\n",
      "Running test case: 50MB - 724823 samples, 1 iterations\n",
      "\n",
      "  size     samples   iters    min     avg     max    used (MB)   total (MB)\n",
      "===========================================================================\n",
      "72 bytes         1     100   0.009   0.009   0.019     489.445    13021.090\n",
      "0.1MB         1449      50   0.015   0.017   0.022     494.137    13021.090\n",
      "10MB        144964       5   0.658   0.670   0.681     556.539    13021.090\n",
      "50MB        724823       1   3.332   3.332   3.332     745.023    13021.090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-21 19:07:41.491115: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "/usr/local/lib/python3.6/dist-packages/distributed/config.py:20: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  defaults = yaml.load(f)\n",
      "tput: terminal attributes: No such device or address\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%sh \n",
    "cd \"/content/mlops-examples/custom_inference/python/boston_housing\" && \n",
    "drum perf-test --code-dir ./src/custom_model --input ./data/boston_housing_inference.csv --target-type regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "79e-llL0L7Aj"
   },
   "source": [
    "# Validation\n",
    "\n",
    "You can validate the model on a set of various checks. It is highly recommended to run these checks, as they are performed in DataRobot before the model can be deployed.\n",
    "\n",
    "List of checks:\n",
    "\n",
    "* null values imputation: each feature of the provided dataset is set to missing and fed to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ms1EF-eeL1MT",
    "outputId": "b753616b-2772-41a9-8e97-ebc16ef1e9a6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-21 19:12:04.192234: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "/usr/local/lib/python3.6/dist-packages/distributed/config.py:20: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  defaults = yaml.load(f)\n",
      "2020-11-21 19:12:07.816878: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "/usr/local/lib/python3.6/dist-packages/distributed/config.py:20: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  defaults = yaml.load(f)\n",
      "2020-11-21 19:12:11.435649: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "/usr/local/lib/python3.6/dist-packages/distributed/config.py:20: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  defaults = yaml.load(f)\n",
      "2020-11-21 19:12:15.026028: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "/usr/local/lib/python3.6/dist-packages/distributed/config.py:20: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  defaults = yaml.load(f)\n",
      "2020-11-21 19:12:18.620085: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "/usr/local/lib/python3.6/dist-packages/distributed/config.py:20: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  defaults = yaml.load(f)\n",
      "2020-11-21 19:12:22.174926: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "/usr/local/lib/python3.6/dist-packages/distributed/config.py:20: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  defaults = yaml.load(f)\n",
      "2020-11-21 19:12:25.720995: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "/usr/local/lib/python3.6/dist-packages/distributed/config.py:20: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  defaults = yaml.load(f)\n",
      "2020-11-21 19:12:29.247623: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "/usr/local/lib/python3.6/dist-packages/distributed/config.py:20: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  defaults = yaml.load(f)\n",
      "2020-11-21 19:12:32.766819: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "/usr/local/lib/python3.6/dist-packages/distributed/config.py:20: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  defaults = yaml.load(f)\n",
      "2020-11-21 19:12:36.290010: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "/usr/local/lib/python3.6/dist-packages/distributed/config.py:20: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  defaults = yaml.load(f)\n",
      "2020-11-21 19:12:39.778233: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "/usr/local/lib/python3.6/dist-packages/distributed/config.py:20: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  defaults = yaml.load(f)\n",
      "2020-11-21 19:12:43.322044: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "/usr/local/lib/python3.6/dist-packages/distributed/config.py:20: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  defaults = yaml.load(f)\n",
      "2020-11-21 19:12:46.868358: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "/usr/local/lib/python3.6/dist-packages/distributed/config.py:20: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  defaults = yaml.load(f)\n"
     ]
    }
   ],
   "source": [
    "%%sh \n",
    "cd \"/content/mlops-examples/custom_inference/python/boston_housing\" && \n",
    "drum validation --code-dir ./src/custom_model --input ./data/boston_housing_inference.csv --target-type regression > validation.log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SDoXgmTLO8S1",
    "outputId": "ffabf38b-2707-40c1-fb84-3f4fbb7391e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       26.850\n",
      "1       26.080\n",
      "2       35.945\n",
      "3       33.580\n",
      "4       35.960\n",
      "5       29.760\n",
      "6       23.830\n",
      "7       24.745\n",
      "8       24.825\n",
      "\n",
      "\n",
      "Validation checks results\n",
      "      Test case         Status\n",
      "==============================\n",
      "Null value imputation   PASSED\n"
     ]
    }
   ],
   "source": [
    "%%sh \n",
    "cd \"/content/mlops-examples/custom_inference/python/boston_housing\" && \n",
    "tail -15 validation.log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t4p0zDG-VWJP"
   },
   "source": [
    "# Batch Scoring with DRUM\n",
    "<a id=\"setup_complete\"></a>\n",
    "\n",
    "At this point our model has been written to disk and we want to use it to make predictions.  To do this, we'll leverage DRUM and its ability to natively handle our Scikit-Learn model. All we need to do is tell DRUM where the model resides and what data we wish to score.  \n",
    "\n",
    "DRUM provides native support for many frameworks. To use DRUM with model frameworks that are not supported out-of-the box, we'll just need to create some custom hooks so DRUM.  In this example, we'll explain some very simple custom hooks and provide links to more complex examples.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C_OOeqEx6hqH",
    "outputId": "8dada72d-3bd7-4086-d859-8d5e772c6886"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/distributed/config.py:20: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  defaults = yaml.load(f)\n",
      "2020-11-21 19:17:57.300319: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "!drum score --code-dir /content/mlops-examples/custom_inference/python/boston_housing/src/custom_model --input /content/mlops-examples/custom_inference/python/boston_housing/data/boston_housing_inference.csv --output /content/mlops-examples/'Custom Model Examples'/'Boston Housing'/data/predictions.csv --target-type regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "pLQnWJw_MrlU",
    "outputId": "dae0ee92-61af-46e8-a778-f165d08eff78"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25.610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22.370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35.155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33.580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35.780</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Predictions\n",
       "0       25.610\n",
       "1       22.370\n",
       "2       35.155\n",
       "3       33.580\n",
       "4       35.780"
      ]
     },
     "execution_count": 23,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"/content/mlops-examples/custom_inference/python/boston_housing/data/predictions.csv\").head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JmS971iweH6t"
   },
   "source": [
    "# Start the inference server locally\n",
    "\n",
    "Batch scoring is very useful; however, the value of DRUM does not stop there.  We can also leverage DRUM to serve our model as a RESTful API endpoint.  The only thing that changes is the way we will structure the command: using the `server` mode instead of `score` mode.  We'll also need to provide an address which is NOT in use.  \n",
    "\n",
    "When starting the server, we'll use `subprocess.Popen` so we may interact with the server in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "D7BrHC1gYjHD"
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import requests\n",
    "import pandas as pd\n",
    "from io import BytesIO\n",
    "import yaml\n",
    "import time\n",
    "import os\n",
    "import datarobot as dr\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "crlRTOHcMrld"
   },
   "outputs": [],
   "source": [
    "run_inference_server = [\"drum\",\n",
    "              \"server\",\n",
    "              \"--code-dir\",\"/content/mlops-examples/custom_inference/python/boston_housing/src/custom_model\", \n",
    "              \"--address\", \"0.0.0.0:6789\", \n",
    "              \"--show-perf\",\n",
    "              \"--target-type\", \"regression\",\n",
    "              \"--logging-level\", \"info\",\n",
    "              \"--show-stacktrace\",\n",
    "              \"--verbose\"\n",
    "              ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "jWvksr_sYlEr"
   },
   "outputs": [],
   "source": [
    "inference_server = subprocess.Popen(run_inference_server, stdout=subprocess.PIPE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "peFenY-leJo3"
   },
   "source": [
    "## Ping the Server to make sure it is running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jmh7SRfQVnTU",
    "outputId": "d38212d1-1681-4218-a5b9-e3313e16e089"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check status\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "b'{\"message\":\"OK\"}\\n'"
      ]
     },
     "execution_count": 27,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## confirm the server is running\n",
    "time.sleep(5) ## snoozing before pinging the server to give it time to actually start\n",
    "print('check status')\n",
    "requests.request(\"GET\", \"http://0.0.0.0:6789/\").content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JOsaTgXOeNMG"
   },
   "source": [
    "## Send data to server for inference\n",
    "\n",
    "The request must provide our dataset as form data.  In order to do so, we'll create a simple Python function to pass the data over appropriately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "iZ-sZcHMYmRx"
   },
   "outputs": [],
   "source": [
    "def score(data, port = \"6789\"):\n",
    "    b_buf = BytesIO()\n",
    "    b_buf.write(data.to_csv(index=False).encode(\"utf-8\"))\n",
    "    b_buf.seek(0)\n",
    "  \n",
    "    url = \"http://localhost:{}/predict/\".format(port)\n",
    "    files = [\n",
    "        ('X', b_buf)\n",
    "    ]\n",
    "    response = requests.request(\"POST\", url, files = files, timeout=None, verify=False)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "nxMXRS5KMrlp"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HjdKXUcUWUXq",
    "outputId": "ba5d493f-837e-4afc-c481-d81017d6303a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'predictions': [25.61,\n",
      "                 22.37,\n",
      "                 35.155,\n",
      "                 33.58,\n",
      "                 35.78,\n",
      "                 27.92,\n",
      "                 21.51,\n",
      "                 24.265,\n",
      "                 16.445]}\n"
     ]
    }
   ],
   "source": [
    "# %%timeit\n",
    "scoring_data = pd.read_csv(\"/content/mlops-examples/custom_inference/python/boston_housing/data/boston_housing_inference.csv\")\n",
    "predictions = score(scoring_data).json() ## score entire dataset but only show first 5 records\n",
    "pprint(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6a20HW9uMrl1",
    "outputId": "b878645f-408d-4bad-9422-31ddef2fac89"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'{\"message\":\"OK\"}\\n'"
      ]
     },
     "execution_count": 30,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "requests.request(\"GET\", \"http://0.0.0.0:6789/\").content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uM8z8v8cTaqD",
    "outputId": "a9b2580d-4dd6-411e-896e-94978bce8b38"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'Server shutting down...'"
      ]
     },
     "execution_count": 31,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "requests.request(\"POST\", \"http://0.0.0.0:6789/shutdown/\").content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OIGQMPjgMrl3"
   },
   "source": [
    "## Value Prop\n",
    "\n",
    "Still wondering why DRUM is beneficial?  First, you don't need to write an API to get a model up and running. Second, DRUM allows you to abstract away the framework (provided you're using one that is natively supported, or that you can write enough Python to instruct DRUM to hook up to the model).  \n",
    "\n",
    "For example, you can hot-swap models as needed (see examples in `./src/other_models`). \n",
    "\n",
    "Below we run through several other frameworks within `score` -- these are also supported in `server` mode!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eHGKKPfNMrl4"
   },
   "source": [
    "#### H2O Mojo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oPxTpC-NMrl4",
    "outputId": "d9d5444e-a109-4f70-aa69-5f4ad527fda2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SLF4J: Failed to load class \"org.slf4j.impl.StaticLoggerBinder\".\n",
      "SLF4J: Defaulting to no-operation (NOP) logger implementation\n",
      "SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details.\n",
      "   Predictions\n",
      "0    24.504000\n",
      "1    22.492000\n",
      "2    34.554001\n",
      "3    34.420001\n",
      "4    35.289001\n",
      "5    28.394001\n",
      "6    21.936000\n",
      "7    23.451000\n",
      "8    17.065000\n"
     ]
    }
   ],
   "source": [
    "!drum score --code-dir /content/mlops-examples/custom_inference/python/boston_housing/src/other_models/h2o_mojo/regression --input /content/mlops-examples/custom_inference/python/boston_housing/data/boston_housing_inference.csv --target-type regression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "35pX5I94Mrl7"
   },
   "source": [
    "#### Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mz6CNMITMrl7",
    "outputId": "18664d29-4948-4727-a0c2-3bb4d43c9dbb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-11-21 19:18:43.315510: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator SimpleImputer from version 0.23.1 when using version 0.22.2.post1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator StandardScaler from version 0.23.1 when using version 0.22.2.post1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator Pipeline from version 0.23.1 when using version 0.22.2.post1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator ColumnTransformer from version 0.23.1 when using version 0.22.2.post1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "2020-11-21 19:18:44.720346: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1\n",
      "2020-11-21 19:18:44.775408: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-11-21 19:18:44.776084: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n",
      "pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5\n",
      "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.73GiB deviceMemoryBandwidth: 298.08GiB/s\n",
      "2020-11-21 19:18:44.776138: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "2020-11-21 19:18:45.008038: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
      "2020-11-21 19:18:45.162308: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
      "2020-11-21 19:18:45.180008: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
      "2020-11-21 19:18:45.462071: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n",
      "2020-11-21 19:18:45.482143: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\n",
      "2020-11-21 19:18:46.009761: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
      "2020-11-21 19:18:46.009973: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-11-21 19:18:46.010642: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-11-21 19:18:46.011209: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\n",
      "2020-11-21 19:18:46.059388: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2200000000 Hz\n",
      "2020-11-21 19:18:46.059591: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2a10f40 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-11-21 19:18:46.059621: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2020-11-21 19:18:46.204727: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-11-21 19:18:46.205480: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2a11100 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2020-11-21 19:18:46.205510: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
      "2020-11-21 19:18:46.206191: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-11-21 19:18:46.206800: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n",
      "pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5\n",
      "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.73GiB deviceMemoryBandwidth: 298.08GiB/s\n",
      "2020-11-21 19:18:46.206856: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "2020-11-21 19:18:46.206899: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
      "2020-11-21 19:18:46.206924: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
      "2020-11-21 19:18:46.206946: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
      "2020-11-21 19:18:46.206966: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n",
      "2020-11-21 19:18:46.206986: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\n",
      "2020-11-21 19:18:46.207008: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
      "2020-11-21 19:18:46.207085: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-11-21 19:18:46.207678: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-11-21 19:18:46.208191: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\n",
      "2020-11-21 19:18:46.210032: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "2020-11-21 19:18:49.981063: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2020-11-21 19:18:49.981120: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 \n",
      "2020-11-21 19:18:49.981132: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N \n",
      "2020-11-21 19:18:49.984782: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-11-21 19:18:49.985389: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-11-21 19:18:49.985937: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2020-11-21 19:18:49.985982: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13962 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
      "2020-11-21 19:18:50,197 WARNING tensorflow:  No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "2020-11-21 19:18:50.446324: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
      "   Predictions\n",
      "0    23.668932\n",
      "1    23.421118\n",
      "2    31.283525\n",
      "3    33.996525\n",
      "4    33.757940\n",
      "5    28.036715\n",
      "6    20.675852\n",
      "7    19.578413\n",
      "8    19.676756\n"
     ]
    }
   ],
   "source": [
    "!drum score --code-dir /content/mlops-examples/custom_inference/python/boston_housing/src/other_models/python3_keras_joblib --input /content/mlops-examples/custom_inference/python/boston_housing/data/boston_housing_inference.csv --target-type regression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PsanmxC-Mrl9"
   },
   "source": [
    "#### XGBoost\n",
    "\n",
    "Requires XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "myCq6e63Mrl-",
    "outputId": "a30ad75a-0608-497e-df9e-7b17746c4ca4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/distributed/config.py:20: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  defaults = yaml.load(f)\n",
      "2020-11-21 19:18:54.373380: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "   Predictions\n",
      "0    24.541843\n",
      "1    21.260277\n",
      "2    34.018497\n",
      "3    32.569200\n",
      "4    34.248066\n",
      "5    27.282364\n",
      "6    20.803959\n",
      "7    19.645220\n",
      "8    16.968880\n"
     ]
    }
   ],
   "source": [
    "!drum score --code-dir /content/mlops-examples/custom_inference/python/boston_housing/src/other_models/python3_xgboost --input /content/mlops-examples/custom_inference/python/boston_housing/data/boston_housing_inference.csv --target-type regression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HGuTZhCZMrmA"
   },
   "source": [
    "#### DataRobot Codegen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7dTPDvBwMrmB",
    "outputId": "24b15a83-a9a6-4a1c-b476-b55ea1e78452"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predictions\n",
      "0    24.258228\n",
      "1    24.258228\n",
      "2    32.451515\n",
      "3    32.451515\n",
      "4    32.451515\n",
      "5    24.258228\n",
      "6    21.078378\n",
      "7    13.107812\n",
      "8    13.107812\n"
     ]
    }
   ],
   "source": [
    "!drum score --code-dir /content/mlops-examples/custom_inference/python/boston_housing/src/other_models/dr_codegen --input /content/mlops-examples/custom_inference/python/boston_housing/data/boston_housing_inference.csv --target-type regression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wjI9pBN5LWoU"
   },
   "source": [
    "# Monitoring Deployments\n",
    "\n",
    "What follows will require a DataRobot account.  You can get a trial account at [https://www.datarobot.com/trial/](https://www.datarobot.com/trial/). \n",
    "\n",
    "Also, JDK 11 or 12 will be required.\n",
    "\n",
    "In this example, we start an agent service locally to monitor a spooler.  The spooler could be something as simple as a local file system, or a little more realistic like a message broker (pubsub, rabbitmq, sqs).  \n",
    "\n",
    "Once the agent is spun-up locally, we enable a few environment variables to let DRUM know that there is an agent present and that it needs to buffer data to the defined spool.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zchJoJBOLWoU"
   },
   "source": [
    "## Getting the MLOps agent\n",
    "We grab the agent through the [DataRobot UI](https://app2.datarobot.com/account/developer-tools). (This link is for the DatRobot Trial. If you have a Managed Cloud or On-prem license, use that to navigate to Developer Tools and select to download External Monitoring Agent.)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8QxLBbBOLWoU"
   },
   "outputs": [],
   "source": [
    "token = \"YOUR_DATAROBOT_API_KEY\"\n",
    "endpoint = \"https://app2.datarobot.com\"\n",
    "## connect to DataRobot platform with python client. \n",
    "client = dr.Client(token, \"{}/api/v2\".format(endpoint))\n",
    "# mlops_agents_tb = client.get(\"mlopsInstaller\")\n",
    "# with open(\"/content/odsc-ml-drum/mlops-agent.tar.gz\", \"wb\") as f:\n",
    "#     f.write(mlops_agents_tb.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "efiBcmSCLWoU"
   },
   "outputs": [],
   "source": [
    "!tar -xf /content/datarobot-mlops-agent-6.2.4-399.tar.gz -C ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N6JE6CwULWoU"
   },
   "source": [
    "## Configuring the Agent\n",
    "\n",
    "To configure the agent, we just need to define the DataRobot MLOps location and our API token.  By default, the agent expects the data to be spooled on the local file system.  Make sure that default location (`/tmp/ta`) exists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TihQis7hLWoU"
   },
   "outputs": [],
   "source": [
    "!mkdir -p /tmp/ta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wJHp7eYXLWoU"
   },
   "outputs": [],
   "source": [
    "agents_dir = \"/content/datarobot-mlops-agent-6.2.4\"\n",
    "with open(r'{}/conf/mlops.agent.conf.yaml'.format(agents_dir)) as file:\n",
    "    documents = yaml.load(file, Loader=yaml.FullLoader)\n",
    "## Configure the location of the mlops instance with which we'll communicate\n",
    "documents['mlopsUrl'] = endpoint\n",
    "# Set your API token\n",
    "documents['apiToken'] = token\n",
    "## Write the configuration back to disk\n",
    "with open('../{}/conf/mlops.agent.conf.yaml'.format(agents_dir), \"w\") as f:\n",
    "    yaml.dump(documents, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B99e8Bn-LWoU"
   },
   "source": [
    "## Start the Agent Service\n",
    "\n",
    "Here we're checking to make sure we can start up the agent's service.  \n",
    "\n",
    "This will require JDK 11 or JDK 12 (these are the tested versions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PZcYvZLLLWoU"
   },
   "outputs": [],
   "source": [
    "## run agents service\n",
    "subprocess.call(\"{}/bin/start-agent.sh\".format(agents_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QxZQyKH7LWoU"
   },
   "outputs": [],
   "source": [
    "## check status\n",
    "check = subprocess.Popen([\"../{}/bin/status-agent.sh\".format(agents_dir)], stdout=subprocess.PIPE)\n",
    "print(check.stdout.readlines())\n",
    "check.terminate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "61QVXMfzLWoU"
   },
   "outputs": [],
   "source": [
    "## check log to see that the agent connected to DR MLOps\n",
    "check = subprocess.Popen([\"cat\", \"../{}/logs/mlops.agent.log\".format(agents_dir)], stdout=subprocess.PIPE)\n",
    "for line in check.stdout.readlines():\n",
    "    print(line)\n",
    "check.terminate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o3VFDnCoLWoU"
   },
   "source": [
    "## DataRobot MLOps - Deploying External Model \n",
    "To communicate with DataRobot MLOps, we need to install the MLOps Python client provided in the downloaded tarball."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4hEKjLNILWoU"
   },
   "outputs": [],
   "source": [
    "!pip install /content/datarobot_mlops_package-*/lib/datarobot*.whl -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q07MhnQuLWoU"
   },
   "outputs": [],
   "source": [
    "from datarobot.mlops.mlops import MLOps\n",
    "from datarobot.mlops.common.enums import OutputType\n",
    "from datarobot.mlops.connected.client import MLOpsClient\n",
    "from datarobot.mlops.common.exception import DRConnectedException\n",
    "from datarobot.mlops.constants import Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ng413Dz4LWoU"
   },
   "outputs": [],
   "source": [
    "DEPLOYMENT_NAME=\"Boston Housing Prices PGH Data Science Meetup\"\n",
    "TRAINING_DATA = '/content/mlops-examples/custom_inference/python/boston_housing/data/boston_housing.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JcPZWE7zLWoU"
   },
   "outputs": [],
   "source": [
    "model_info = {\n",
    "        \"name\": \"Boston Housing Pricing\",\n",
    "        \"modelDescription\": {\n",
    "            \"description\": \"prediction price of home\"\n",
    "        },\n",
    "        \"target\": {\n",
    "            \"type\": \"Regression\",\n",
    "            \"name\": \"MEDV\",\n",
    "        }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ocIMxnFBLWoU"
   },
   "outputs": [],
   "source": [
    "# Create and connect the client\n",
    "mlops_client = MLOpsClient(endpoint, token)\n",
    "\n",
    "# Add training_data to model configuration\n",
    "print(\"Uploading training data - {}. This may take some time...\".format(TRAINING_DATA))\n",
    "dataset_id = mlops_client.upload_dataset(TRAINING_DATA)\n",
    "print(\"Training dataset uploaded. Catalog ID {}.\".format(dataset_id))\n",
    "model_info[\"datasets\"] = {\"trainingDataCatalogId\": dataset_id}\n",
    "\n",
    "# Create the model package\n",
    "print('Create model package')\n",
    "model_pkg_id = mlops_client.create_model_package(model_info)\n",
    "model_pkg = mlops_client.get_model_package(model_pkg_id)\n",
    "model_id = model_pkg[\"modelId\"]\n",
    "\n",
    "# Deploy the model package\n",
    "print('Deploy model package')\n",
    "deployment_id = mlops_client.deploy_model_package(model_pkg[\"id\"],\n",
    "                                                            DEPLOYMENT_NAME)\n",
    "\n",
    "# Enable data drift tracking\n",
    "print('Enable feature drift')\n",
    "enable_feature_drift = TRAINING_DATA is not None\n",
    "mlops_client.update_deployment_settings(deployment_id, target_drift=True,\n",
    "                                                  feature_drift=enable_feature_drift)\n",
    "_ = mlops_client.get_deployment_settings(deployment_id)\n",
    "\n",
    "print(\"\\nDone.\")\n",
    "print(\"DEPLOYMENT_ID=%s, MODEL_ID=%s\" % (deployment_id, model_id))\n",
    "\n",
    "DEPLOYMENT_ID = deployment_id\n",
    "MODEL_ID = model_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KOBqlySiLWoU"
   },
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "link = \"{}/deployments/{}/overview\".format(endpoint,deployment_id)\n",
    "# display(HTML(\"\"\"<a href=\"{link}\">{link}</a>\"\"\".format( link=link )))\n",
    "print(link)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZXzITNMpLWoU"
   },
   "source": [
    "# Adding Monitoring with MLOps Agent\n",
    "\n",
    "## Monitoring with DRUM\n",
    "\n",
    "There are a few additional parameters that we should set for the command line utility; or we can just create environment variables and allow DRUM to pick up the details from there.  \n",
    "\n",
    "```\n",
    "  --monitor             Monitor predictions using DataRobot MLOps. True or\n",
    "                        False. (env: MONITOR). Monitoring cannot be used in\n",
    "                        unstructured mode.\n",
    "  --deployment-id DEPLOYMENT_ID\n",
    "                        Deployment ID to use for monitoring model predictions\n",
    "                        (env: DEPLOYMENT_ID)\n",
    "  --model-id MODEL_ID   MLOps model ID to use for monitoring predictions (env:\n",
    "                        MODEL_ID)\n",
    "  --monitor-settings MONITOR_SETTINGS\n",
    "                        MLOps setting to use for connecting with the MLOps\n",
    "                        agent (env: MONITOR_SETTINGS)\n",
    "```\n",
    "For this example, we'll just set environment variables to add monitoring. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H69eqzZ0LWoU"
   },
   "outputs": [],
   "source": [
    "os.environ[\"MONITOR\"] = \"True\"\n",
    "os.environ[\"DEPLOYMENT_ID\"] = deployment_id\n",
    "os.environ[\"MODEL_ID\"] = model_id\n",
    "os.environ[\"MONITOR_SETTINGS\"] = \"spooler_type=filesystem;directory=/tmp/ta;max_files=5;file_max_size=1045876000\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_YYuOnsKLWoU"
   },
   "outputs": [],
   "source": [
    "run_inference_server = [\"drum\",\n",
    "              \"server\",\n",
    "              \"--code-dir\",\"/content/mlops-examples/custom_inference/python/boston_housing/src/custom_model\", \n",
    "              \"--address\", \"0.0.0.0:43210\", \n",
    "              \"--show-perf\",\n",
    "              \"--target-type\", \"regression\",\n",
    "              \"--logging-level\", \"info\",\n",
    "              \"--show-stacktrace\",\n",
    "#               \"--verbose\"\n",
    "              ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QlrKfJifLWoU"
   },
   "outputs": [],
   "source": [
    "inference_server_with_monitoring = subprocess.Popen(run_inference_server, stdout=subprocess.PIPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lKX7_2L5LWoU"
   },
   "outputs": [],
   "source": [
    "predictions = score(\n",
    "    pd.read_csv(\"/content/mlops-examples/custom_inference/python/boston_housing/data/boston_housing.csv\").drop([\"MEDV\"],axis=1).head(100),\n",
    "    \"43210\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qhTHBqeoLWoU"
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(predictions.json()).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mzPaJo5XLWoU"
   },
   "outputs": [],
   "source": [
    "requests.post(\"http://localhost:43210/shutdown/\").content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OHt8CMTxLWoU"
   },
   "outputs": [],
   "source": [
    "subprocess.call(\"../{}/bin/stop-agent.sh\".format(agents_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zgxxiq6WLWoU"
   },
   "outputs": [],
   "source": [
    "## check that agent is stopped \n",
    "check = subprocess.Popen([\"../{}/bin/status-agent.sh\".format(agents_dir)], stdout=subprocess.PIPE)\n",
    "print(check.stdout.readlines())\n",
    "check.terminate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eoTiXvWrLWoU"
   },
   "outputs": [],
   "source": [
    "deployment = dr.Deployment.get(deployment_id)\n",
    "deployment.get_service_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kgNzsJ6XLWoU"
   },
   "outputs": [],
   "source": [
    "service_stats = deployment.get_service_stats()\n",
    "service_stats.metrics"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "DRUM - Automated Model Serving Made Easy.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
